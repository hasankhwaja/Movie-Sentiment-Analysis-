{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":3087,"status":"ok","timestamp":1732302669521,"user":{"displayName":"Rishub Talreja","userId":"10598265381735131476"},"user_tz":300},"id":"akEeBGXSxsPQ"},"outputs":[],"source":["!pip install -U -q PyDrive\n"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":38896,"status":"ok","timestamp":1732302708414,"user":{"displayName":"Rishub Talreja","userId":"10598265381735131476"},"user_tz":300},"id":"NX0eT5qe2Y9B","outputId":"10e2ec12-1a0d-41df-f0ea-948132025a7d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:root:pydrive is deprecated and no longer maintained. We recommend that you migrate your projects to pydrive2, the maintained fork of pydrive\n"]}],"source":["'''from google.colab import drive\n","drive.mount('/content/drive')\n","\n","\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","\n","\n","# Authenticate and create the PyDrive client.\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)'''\n"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":8495,"status":"ok","timestamp":1732302716906,"user":{"displayName":"Rishub Talreja","userId":"10598265381735131476"},"user_tz":300},"id":"wfRal0Hn2bIJ"},"outputs":[],"source":["'''link = 'https://drive.google.com/file/d/1l_5o4Bkbs3Uab_WezeCoo2C3JCb8BrBc/view'\n","\n","import pandas as pd\n","\n","# to get the id part of the file\n","id = link.split(\"/\")[-2]\n","downloaded = drive.CreateFile({'id':id})\n","downloaded.GetContentFile('train.tsv')\n","train = pd.read_csv('train.tsv', sep = '\\t')\n","#########\n","link = 'https://drive.google.com/file/d/1ID_g_xHfJ2NkXLIxAnL9m05pCaDHSteH/view'\n","id = link.split(\"/\")[-2]\n","downloaded = drive.CreateFile({'id':id})\n","downloaded.GetContentFile('test.tsv')\n","\n","test = pd.read_csv('test.tsv', sep = '\\t')'''"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7817,"status":"ok","timestamp":1732302724721,"user":{"displayName":"Rishub Talreja","userId":"10598265381735131476"},"user_tz":300},"id":"ge7gLJqFxsPQ","outputId":"d48b9259-1bee-447b-8785-c06d2555a7d7"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package punkt to\n","[nltk_data]     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Unzipping tokenizers\\punkt.zip.\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n","[nltk_data] Downloading package stopwords to\n","[nltk_data]     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Unzipping corpora\\stopwords.zip.\n","[nltk_data] Downloading package wordnet to\n","[nltk_data]     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n"]},{"data":{"text/plain":["True"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["import pandas as pd\n","import numpy as np\n","import nltk\n","from nltk.tokenize import word_tokenize\n","from nltk import pos_tag\n","from nltk.corpus import stopwords\n","from nltk.stem import WordNetLemmatizer\n","from sklearn.preprocessing import LabelEncoder\n","from collections import defaultdict\n","from nltk.corpus import wordnet as wn\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn import model_selection, naive_bayes, svm\n","from sklearn.metrics import accuracy_score\n","\n","nltk.download('punkt')\n","nltk.download('averaged_perceptron_tagger')\n","nltk.download('stopwords')\n","nltk.download('wordnet') #Testing 123\n","\n","#https://medium.com/@bedigunjit/simple-guide-to-text-classification-nlp-using-svm-and-naive-bayes-with-python-421db3a72d34"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":66864,"status":"ok","timestamp":1732302791583,"user":{"displayName":"Rishub Talreja","userId":"10598265381735131476"},"user_tz":300},"id":"Fve4_TFH6G4m","outputId":"7358dc5e-6903-4c92-d575-1f5f9b774a2f"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package punkt to\n","[nltk_data]     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n","[nltk_data]       date!\n","[nltk_data] Downloading package stopwords to\n","[nltk_data]     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package wordnet to\n","[nltk_data]     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","[nltk_data] Downloading package punkt_tab to\n","[nltk_data]     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n","[nltk_data] Downloading collection 'all'\n","[nltk_data]    | \n","[nltk_data]    | Downloading package abc to\n","[nltk_data]    |     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]    |   Unzipping corpora\\abc.zip.\n","[nltk_data]    | Downloading package alpino to\n","[nltk_data]    |     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]    |   Unzipping corpora\\alpino.zip.\n","[nltk_data]    | Downloading package averaged_perceptron_tagger to\n","[nltk_data]    |     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n","[nltk_data]    |       to-date!\n","[nltk_data]    | Downloading package averaged_perceptron_tagger_eng to\n","[nltk_data]    |     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]    |   Unzipping\n","[nltk_data]    |       taggers\\averaged_perceptron_tagger_eng.zip.\n","[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n","[nltk_data]    |     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]    |   Unzipping\n","[nltk_data]    |       taggers\\averaged_perceptron_tagger_ru.zip.\n","[nltk_data]    | Downloading package averaged_perceptron_tagger_rus to\n","[nltk_data]    |     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]    |   Unzipping\n","[nltk_data]    |       taggers\\averaged_perceptron_tagger_rus.zip.\n","[nltk_data]    | Downloading package basque_grammars to\n","[nltk_data]    |     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]    |   Unzipping grammars\\basque_grammars.zip.\n","[nltk_data]    | Downloading package bcp47 to\n","[nltk_data]    |     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]    | Downloading package biocreative_ppi to\n","[nltk_data]    |     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]    |   Unzipping corpora\\biocreative_ppi.zip.\n","[nltk_data]    | Downloading package bllip_wsj_no_aux to\n","[nltk_data]    |     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]    |   Unzipping models\\bllip_wsj_no_aux.zip.\n","[nltk_data]    | Downloading package book_grammars to\n","[nltk_data]    |     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]    |   Unzipping grammars\\book_grammars.zip.\n","[nltk_data]    | Downloading package brown to\n","[nltk_data]    |     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]    |   Unzipping corpora\\brown.zip.\n","[nltk_data]    | Downloading package brown_tei to\n","[nltk_data]    |     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]    |   Unzipping corpora\\brown_tei.zip.\n","[nltk_data]    | Downloading package cess_cat to\n","[nltk_data]    |     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]    |   Unzipping corpora\\cess_cat.zip.\n","[nltk_data]    | Downloading package cess_esp to\n","[nltk_data]    |     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]    |   Unzipping corpora\\cess_esp.zip.\n","[nltk_data]    | Downloading package chat80 to\n","[nltk_data]    |     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]    |   Unzipping corpora\\chat80.zip.\n","[nltk_data]    | Downloading package city_database to\n","[nltk_data]    |     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]    |   Unzipping corpora\\city_database.zip.\n","[nltk_data]    | Downloading package cmudict to\n","[nltk_data]    |     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]    |   Unzipping corpora\\cmudict.zip.\n","[nltk_data]    | Downloading package comparative_sentences to\n","[nltk_data]    |     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]    |   Unzipping corpora\\comparative_sentences.zip.\n","[nltk_data]    | Downloading package comtrans to\n","[nltk_data]    |     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]    | Downloading package conll2000 to\n","[nltk_data]    |     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]    |   Unzipping corpora\\conll2000.zip.\n","[nltk_data]    | Downloading package conll2002 to\n","[nltk_data]    |     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]    |   Unzipping corpora\\conll2002.zip.\n","[nltk_data]    | Downloading package conll2007 to\n","[nltk_data]    |     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]    | Downloading package crubadan to\n","[nltk_data]    |     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]    |   Unzipping corpora\\crubadan.zip.\n","[nltk_data]    | Downloading package dependency_treebank to\n","[nltk_data]    |     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]    |   Unzipping corpora\\dependency_treebank.zip.\n","[nltk_data]    | Downloading package dolch to\n","[nltk_data]    |     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]    |   Unzipping corpora\\dolch.zip.\n","[nltk_data]    | Downloading package europarl_raw to\n","[nltk_data]    |     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]    |   Unzipping corpora\\europarl_raw.zip.\n","[nltk_data]    | Downloading package extended_omw to\n","[nltk_data]    |     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]    | Downloading package floresta to\n","[nltk_data]    |     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]    |   Unzipping corpora\\floresta.zip.\n","[nltk_data]    | Downloading package framenet_v15 to\n","[nltk_data]    |     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]    |   Unzipping corpora\\framenet_v15.zip.\n","[nltk_data]    | Downloading package framenet_v17 to\n","[nltk_data]    |     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]    |   Unzipping corpora\\framenet_v17.zip.\n","[nltk_data]    | Downloading package gazetteers to\n","[nltk_data]    |     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]    |   Unzipping corpora\\gazetteers.zip.\n","[nltk_data]    | Downloading package genesis to\n","[nltk_data]    |     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]    |   Unzipping corpora\\genesis.zip.\n","[nltk_data]    | Downloading package gutenberg to\n","[nltk_data]    |     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]    |   Unzipping corpora\\gutenberg.zip.\n","[nltk_data]    | Downloading package ieer to\n","[nltk_data]    |     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]    |   Unzipping corpora\\ieer.zip.\n","[nltk_data]    | Downloading package inaugural to\n","[nltk_data]    |     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]    |   Unzipping corpora\\inaugural.zip.\n","[nltk_data]    | Downloading package indian to\n","[nltk_data]    |     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]    |   Unzipping corpora\\indian.zip.\n","[nltk_data]    | Downloading package jeita to\n","[nltk_data]    |     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]    | Downloading package kimmo to\n","[nltk_data]    |     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]    |   Unzipping corpora\\kimmo.zip.\n","[nltk_data]    | Downloading package knbc to\n","[nltk_data]    |     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]    | Downloading package large_grammars to\n","[nltk_data]    |     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]    |   Unzipping grammars\\large_grammars.zip.\n","[nltk_data]    | Downloading package lin_thesaurus to\n","[nltk_data]    |     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]    |   Unzipping corpora\\lin_thesaurus.zip.\n","[nltk_data]    | Downloading package mac_morpho to\n","[nltk_data]    |     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]    |   Unzipping corpora\\mac_morpho.zip.\n","[nltk_data]    | Downloading package machado to\n","[nltk_data]    |     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]    | Downloading package masc_tagged to\n","[nltk_data]    |     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]    | Downloading package maxent_ne_chunker to\n","[nltk_data]    |     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]    |   Unzipping chunkers\\maxent_ne_chunker.zip.\n","[nltk_data]    | Downloading package maxent_ne_chunker_tab to\n","[nltk_data]    |     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]    |   Unzipping chunkers\\maxent_ne_chunker_tab.zip.\n","[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n","[nltk_data]    |     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]    |   Unzipping taggers\\maxent_treebank_pos_tagger.zip.\n","[nltk_data]    | Downloading package maxent_treebank_pos_tagger_tab to\n","[nltk_data]    |     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]    |   Unzipping\n","[nltk_data]    |       taggers\\maxent_treebank_pos_tagger_tab.zip.\n","[nltk_data]    | Downloading package moses_sample to\n","[nltk_data]    |     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]    |   Unzipping models\\moses_sample.zip.\n","[nltk_data]    | Downloading package movie_reviews to\n","[nltk_data]    |     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]    |   Unzipping corpora\\movie_reviews.zip.\n","[nltk_data]    | Downloading package mte_teip5 to\n","[nltk_data]    |     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]    |   Unzipping corpora\\mte_teip5.zip.\n","[nltk_data]    | Downloading package mwa_ppdb to\n","[nltk_data]    |     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]    |   Unzipping misc\\mwa_ppdb.zip.\n","[nltk_data]    | Downloading package names to\n","[nltk_data]    |     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]    |   Unzipping corpora\\names.zip.\n","[nltk_data]    | Downloading package nombank.1.0 to\n","[nltk_data]    |     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]    | Downloading package nonbreaking_prefixes to\n","[nltk_data]    |     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]    |   Unzipping corpora\\nonbreaking_prefixes.zip.\n","[nltk_data]    | Downloading package nps_chat to\n","[nltk_data]    |     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]    |   Unzipping corpora\\nps_chat.zip.\n","[nltk_data]    | Downloading package omw to\n","[nltk_data]    |     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]    | Downloading package omw-1.4 to\n","[nltk_data]    |     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]    | Downloading package opinion_lexicon to\n","[nltk_data]    |     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]    |   Unzipping corpora\\opinion_lexicon.zip.\n","[nltk_data]    | Downloading package panlex_swadesh to\n","[nltk_data]    |     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]    | Downloading package paradigms to\n","[nltk_data]    |     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]    |   Unzipping corpora\\paradigms.zip.\n","[nltk_data]    | Downloading package pe08 to\n","[nltk_data]    |     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]    |   Unzipping corpora\\pe08.zip.\n","[nltk_data]    | Downloading package perluniprops to\n","[nltk_data]    |     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]    |   Unzipping misc\\perluniprops.zip.\n","[nltk_data]    | Downloading package pil to\n","[nltk_data]    |     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]    |   Unzipping corpora\\pil.zip.\n","[nltk_data]    | Downloading package pl196x to\n","[nltk_data]    |     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]    |   Unzipping corpora\\pl196x.zip.\n","[nltk_data]    | Downloading package porter_test to\n","[nltk_data]    |     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]    |   Unzipping stemmers\\porter_test.zip.\n","[nltk_data]    | Downloading package ppattach to\n","[nltk_data]    |     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]    |   Unzipping corpora\\ppattach.zip.\n","[nltk_data]    | Downloading package problem_reports to\n","[nltk_data]    |     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]    |   Unzipping corpora\\problem_reports.zip.\n","[nltk_data]    | Downloading package product_reviews_1 to\n","[nltk_data]    |     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]    |   Unzipping corpora\\product_reviews_1.zip.\n","[nltk_data]    | Downloading package product_reviews_2 to\n","[nltk_data]    |     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]    |   Unzipping corpora\\product_reviews_2.zip.\n","[nltk_data]    | Downloading package propbank to\n","[nltk_data]    |     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]    | Downloading package pros_cons to\n","[nltk_data]    |     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]    |   Unzipping corpora\\pros_cons.zip.\n","[nltk_data]    | Downloading package ptb to\n","[nltk_data]    |     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]    |   Unzipping corpora\\ptb.zip.\n","[nltk_data]    | Downloading package punkt to\n","[nltk_data]    |     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]    |   Package punkt is already up-to-date!\n","[nltk_data]    | Downloading package punkt_tab to\n","[nltk_data]    |     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]    |   Package punkt_tab is already up-to-date!\n","[nltk_data]    | Downloading package qc to\n","[nltk_data]    |     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]    |   Unzipping corpora\\qc.zip.\n","[nltk_data]    | Downloading package reuters to\n","[nltk_data]    |     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]    | Downloading package rslp to\n","[nltk_data]    |     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]    |   Unzipping stemmers\\rslp.zip.\n","[nltk_data]    | Downloading package rte to\n","[nltk_data]    |     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]    |   Unzipping corpora\\rte.zip.\n","[nltk_data]    | Downloading package sample_grammars to\n","[nltk_data]    |     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]    |   Unzipping grammars\\sample_grammars.zip.\n","[nltk_data]    | Downloading package semcor to\n","[nltk_data]    |     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]    | Downloading package senseval to\n","[nltk_data]    |     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]    |   Unzipping corpora\\senseval.zip.\n","[nltk_data]    | Downloading package sentence_polarity to\n","[nltk_data]    |     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]    |   Unzipping corpora\\sentence_polarity.zip.\n","[nltk_data]    | Downloading package sentiwordnet to\n","[nltk_data]    |     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]    |   Unzipping corpora\\sentiwordnet.zip.\n","[nltk_data]    | Downloading package shakespeare to\n","[nltk_data]    |     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]    |   Unzipping corpora\\shakespeare.zip.\n","[nltk_data]    | Downloading package sinica_treebank to\n","[nltk_data]    |     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]    |   Unzipping corpora\\sinica_treebank.zip.\n","[nltk_data]    | Downloading package smultron to\n","[nltk_data]    |     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]    |   Unzipping corpora\\smultron.zip.\n","[nltk_data]    | Downloading package snowball_data to\n","[nltk_data]    |     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]    | Downloading package spanish_grammars to\n","[nltk_data]    |     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]    |   Unzipping grammars\\spanish_grammars.zip.\n","[nltk_data]    | Downloading package state_union to\n","[nltk_data]    |     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]    |   Unzipping corpora\\state_union.zip.\n","[nltk_data]    | Downloading package stopwords to\n","[nltk_data]    |     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]    |   Package stopwords is already up-to-date!\n","[nltk_data]    | Downloading package subjectivity to\n","[nltk_data]    |     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]    |   Unzipping corpora\\subjectivity.zip.\n","[nltk_data]    | Downloading package swadesh to\n","[nltk_data]    |     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]    |   Unzipping corpora\\swadesh.zip.\n","[nltk_data]    | Downloading package switchboard to\n","[nltk_data]    |     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]    |   Unzipping corpora\\switchboard.zip.\n","[nltk_data]    | Downloading package tagsets to\n","[nltk_data]    |     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]    |   Unzipping help\\tagsets.zip.\n","[nltk_data]    | Downloading package tagsets_json to\n","[nltk_data]    |     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]    |   Unzipping help\\tagsets_json.zip.\n","[nltk_data]    | Downloading package timit to\n","[nltk_data]    |     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]    |   Unzipping corpora\\timit.zip.\n","[nltk_data]    | Downloading package toolbox to\n","[nltk_data]    |     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]    |   Unzipping corpora\\toolbox.zip.\n","[nltk_data]    | Downloading package treebank to\n","[nltk_data]    |     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]    |   Unzipping corpora\\treebank.zip.\n","[nltk_data]    | Downloading package twitter_samples to\n","[nltk_data]    |     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]    |   Unzipping corpora\\twitter_samples.zip.\n","[nltk_data]    | Downloading package udhr to\n","[nltk_data]    |     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]    |   Unzipping corpora\\udhr.zip.\n","[nltk_data]    | Downloading package udhr2 to\n","[nltk_data]    |     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]    |   Unzipping corpora\\udhr2.zip.\n","[nltk_data]    | Downloading package unicode_samples to\n","[nltk_data]    |     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]    |   Unzipping corpora\\unicode_samples.zip.\n","[nltk_data]    | Downloading package universal_tagset to\n","[nltk_data]    |     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]    |   Unzipping taggers\\universal_tagset.zip.\n","[nltk_data]    | Downloading package universal_treebanks_v20 to\n","[nltk_data]    |     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]    | Downloading package vader_lexicon to\n","[nltk_data]    |     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]    | Downloading package verbnet to\n","[nltk_data]    |     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]    |   Unzipping corpora\\verbnet.zip.\n","[nltk_data]    | Downloading package verbnet3 to\n","[nltk_data]    |     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]    |   Unzipping corpora\\verbnet3.zip.\n","[nltk_data]    | Downloading package webtext to\n","[nltk_data]    |     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]    |   Unzipping corpora\\webtext.zip.\n","[nltk_data]    | Downloading package wmt15_eval to\n","[nltk_data]    |     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]    |   Unzipping models\\wmt15_eval.zip.\n","[nltk_data]    | Downloading package word2vec_sample to\n","[nltk_data]    |     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]    |   Unzipping models\\word2vec_sample.zip.\n","[nltk_data]    | Downloading package wordnet to\n","[nltk_data]    |     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]    |   Package wordnet is already up-to-date!\n","[nltk_data]    | Downloading package wordnet2021 to\n","[nltk_data]    |     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]    | Downloading package wordnet2022 to\n","[nltk_data]    |     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]    |   Unzipping corpora\\wordnet2022.zip.\n","[nltk_data]    | Downloading package wordnet31 to\n","[nltk_data]    |     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]    | Downloading package wordnet_ic to\n","[nltk_data]    |     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]    |   Unzipping corpora\\wordnet_ic.zip.\n","[nltk_data]    | Downloading package words to\n","[nltk_data]    |     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]    |   Unzipping corpora\\words.zip.\n","[nltk_data]    | Downloading package ycoe to\n","[nltk_data]    |     C:\\Users\\Rishub\\AppData\\Roaming\\nltk_data...\n","[nltk_data]    |   Unzipping corpora\\ycoe.zip.\n","[nltk_data]    | \n","[nltk_data]  Done downloading collection all\n"]}],"source":["# Step 1: Import libraries\n","import pandas as pd\n","import numpy as np\n","import nltk\n","from nltk.tokenize import word_tokenize\n","from nltk.corpus import stopwords\n","from nltk.stem import WordNetLemmatizer\n","from sklearn.model_selection import train_test_split\n","\n","# Step 2: Download NLTK resources\n","nltk.download('punkt')  # For tokenization\n","nltk.download('averaged_perceptron_tagger')  # For POS tagging (optional)\n","nltk.download('stopwords')  # For stopword removal\n","nltk.download('wordnet')  # For lemmatization\n","nltk.download('punkt_tab')\n","nltk.download('all')\n","\n","train = pd.read_csv('train.tsv', sep = '\\t')\n","test = pd.read_csv('test.tsv', sep = '\\t')"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":377418,"status":"ok","timestamp":1732303168992,"user":{"displayName":"Rishub Talreja","userId":"10598265381735131476"},"user_tz":300},"id":"gTOUsb5hxsPR"},"outputs":[],"source":["\n","np.random.seed(123)\n","X_train = train.iloc[:, 0:-1]\n","y_train = train.iloc[:, -1]\n","x_test = test\n","\n","\n","X_train['Phrase'].dropna(inplace=True) #remove blank rows\n","X_train['Phrase'] = [word.lower() for word in X_train['Phrase']] #make everything lowercase\n","X_train['Phrase'] = [word_tokenize(pharse) for pharse in X_train['Phrase']] #Each phrase is broken into a set of words\n","\n","\n","#\n","#All FOR TRAINING DATA\n","#\n","\n","#Trying to see if each word is a noun, verb or adjective\n","tag_map = defaultdict(lambda : wn.NOUN)\n","tag_map['J'] = wn.ADJ\n","tag_map['V'] = wn.VERB\n","tag_map['R'] = wn.ADV\n","\n","for index,entry in enumerate(X_train['Phrase']):\n","    # Declaring Empty List to store the words that follow the rules for this step\n","    Final_words = []\n","    # Initializing WordNetLemmatizer()\n","    word_Lemmatized = WordNetLemmatizer()\n","    # pos_tag function below will provide the 'tag' i.e if the word is Noun(N) or Verb(V) or something else.\n","    for word, tag in pos_tag(entry):\n","        # Below condition is to check for Stop words and consider only alphabets\n","        if word not in stopwords.words('english') and word.isalpha():\n","            word_Final = word_Lemmatized.lemmatize(word,tag_map[tag[0]])\n","            Final_words.append(word_Final)\n","    # The final processed set of words for each iteration will be stored in 'text_final'\n","    X_train.loc[index,'text_final'] = str(Final_words)\n","\n","#\n","#SAME THING FOR TEST DATA]\n","X_test = test\n","X_test['Phrase'].dropna(inplace=True) #remove blank rows\n","X_test['Phrase'] = X_test['Phrase'].astype(str)\n","X_test['Phrase'] = [word.lower() for word in X_test['Phrase']] #make everything lowercase\n","X_test['Phrase'] = [word_tokenize(pharse) for pharse in X_test['Phrase']] #Each phrase is broken into a set of words\n","\n","for index,entry in enumerate(X_test['Phrase']):\n","    Final_words = []\n","    word_Lemmatized = WordNetLemmatizer()\n","    for word, tag in pos_tag(entry):\n","        if word not in stopwords.words('english') and word.isalpha():\n","            word_Final = word_Lemmatized.lemmatize(word,tag_map[tag[0]])\n","            Final_words.append(word_Final)\n","    X_test.loc[index,'text_final'] = str(Final_words)\n","\n","\n","\n","\n"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1732303168993,"user":{"displayName":"Rishub Talreja","userId":"10598265381735131476"},"user_tz":300},"id":"whTA0jpVxsPS","outputId":"8fdf93d5-c88f-4dd9-fe60-43f17303956c"},"outputs":[{"name":"stdout","output_type":"stream","text":["156060\n","156060\n","[<class 'str'>]\n","Shape of X_train: (156060, 4)\n","Length of y_train: 156060\n"]}],"source":["#y_train = y_train.to_numpy() #Turn the sentiment scores of the df into an array\n","\n","print(len(X_train))\n","print(len(y_train))\n","# Convert lists of tokens into strings\n","X_train['text_final'] = X_train['text_final'].apply(lambda x: ' '.join(x) if isinstance(x, list) else x)\n","X_test['text_final'] = X_test['text_final'].apply(lambda x: ' '.join(x) if isinstance(x, list) else x)\n","\n","y_train.dropna(inplace=True)\n","\n","Encoder = LabelEncoder()\n","Encoder = LabelEncoder()\n","Train_Y = Encoder.fit_transform(y_train)\n","\n","print(X_train['text_final'].apply(type).unique())\n","\n","# Remove rows where 'text_final' is an empty string or contains only whitespace\n","X_train = X_train[X_train['text_final'].apply(lambda x: isinstance(x, str) and len(x.strip()) > 0)]\n","y_train = y_train[X_train.index]  # Ensure y_train is aligned with X_train after filtering\n","\n","# Now, confirm the lengths again\n","print(\"Shape of X_train:\", X_train.shape)\n","print(\"Length of y_train:\", len(y_train))\n","\n","\n","\n"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2036,"status":"ok","timestamp":1732303171026,"user":{"displayName":"Rishub Talreja","userId":"10598265381735131476"},"user_tz":300},"id":"wlx-tjVkxsPS","outputId":"9d06b534-d650-4570-9f53-f9c1b8c8af21"},"outputs":[{"name":"stdout","output_type":"stream","text":["Shape of Train_X_Tfidf: (156060, 5000)\n","Length of y_train: 156060\n"]}],"source":["# Re-run the TF-IDF vectorization after ensuring that 'text_final' is valid\n","Tfidf_vect = TfidfVectorizer(max_features=5000)\n","Train_X_Tfidf = Tfidf_vect.fit_transform(X_train['text_final'])\n","Test_X_Tfidf = Tfidf_vect.transform(X_test['text_final'])\n","\n","# Check the shapes after transformation\n","print(\"Shape of Train_X_Tfidf:\", Train_X_Tfidf.shape)\n","print(\"Length of y_train:\", len(y_train))\n","\n","\n"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"background_save":true},"id":"0A3KXl2SBEES"},"outputs":[{"data":{"text/html":["<style>#sk-container-id-1 {\n","  /* Definition of color scheme common for light and dark mode */\n","  --sklearn-color-text: black;\n","  --sklearn-color-line: gray;\n","  /* Definition of color scheme for unfitted estimators */\n","  --sklearn-color-unfitted-level-0: #fff5e6;\n","  --sklearn-color-unfitted-level-1: #f6e4d2;\n","  --sklearn-color-unfitted-level-2: #ffe0b3;\n","  --sklearn-color-unfitted-level-3: chocolate;\n","  /* Definition of color scheme for fitted estimators */\n","  --sklearn-color-fitted-level-0: #f0f8ff;\n","  --sklearn-color-fitted-level-1: #d4ebff;\n","  --sklearn-color-fitted-level-2: #b3dbfd;\n","  --sklearn-color-fitted-level-3: cornflowerblue;\n","\n","  /* Specific color for light theme */\n","  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n","  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n","  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n","  --sklearn-color-icon: #696969;\n","\n","  @media (prefers-color-scheme: dark) {\n","    /* Redefinition of color scheme for dark theme */\n","    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n","    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n","    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n","    --sklearn-color-icon: #878787;\n","  }\n","}\n","\n","#sk-container-id-1 {\n","  color: var(--sklearn-color-text);\n","}\n","\n","#sk-container-id-1 pre {\n","  padding: 0;\n","}\n","\n","#sk-container-id-1 input.sk-hidden--visually {\n","  border: 0;\n","  clip: rect(1px 1px 1px 1px);\n","  clip: rect(1px, 1px, 1px, 1px);\n","  height: 1px;\n","  margin: -1px;\n","  overflow: hidden;\n","  padding: 0;\n","  position: absolute;\n","  width: 1px;\n","}\n","\n","#sk-container-id-1 div.sk-dashed-wrapped {\n","  border: 1px dashed var(--sklearn-color-line);\n","  margin: 0 0.4em 0.5em 0.4em;\n","  box-sizing: border-box;\n","  padding-bottom: 0.4em;\n","  background-color: var(--sklearn-color-background);\n","}\n","\n","#sk-container-id-1 div.sk-container {\n","  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n","     but bootstrap.min.css set `[hidden] { display: none !important; }`\n","     so we also need the `!important` here to be able to override the\n","     default hidden behavior on the sphinx rendered scikit-learn.org.\n","     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n","  display: inline-block !important;\n","  position: relative;\n","}\n","\n","#sk-container-id-1 div.sk-text-repr-fallback {\n","  display: none;\n","}\n","\n","div.sk-parallel-item,\n","div.sk-serial,\n","div.sk-item {\n","  /* draw centered vertical line to link estimators */\n","  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n","  background-size: 2px 100%;\n","  background-repeat: no-repeat;\n","  background-position: center center;\n","}\n","\n","/* Parallel-specific style estimator block */\n","\n","#sk-container-id-1 div.sk-parallel-item::after {\n","  content: \"\";\n","  width: 100%;\n","  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n","  flex-grow: 1;\n","}\n","\n","#sk-container-id-1 div.sk-parallel {\n","  display: flex;\n","  align-items: stretch;\n","  justify-content: center;\n","  background-color: var(--sklearn-color-background);\n","  position: relative;\n","}\n","\n","#sk-container-id-1 div.sk-parallel-item {\n","  display: flex;\n","  flex-direction: column;\n","}\n","\n","#sk-container-id-1 div.sk-parallel-item:first-child::after {\n","  align-self: flex-end;\n","  width: 50%;\n","}\n","\n","#sk-container-id-1 div.sk-parallel-item:last-child::after {\n","  align-self: flex-start;\n","  width: 50%;\n","}\n","\n","#sk-container-id-1 div.sk-parallel-item:only-child::after {\n","  width: 0;\n","}\n","\n","/* Serial-specific style estimator block */\n","\n","#sk-container-id-1 div.sk-serial {\n","  display: flex;\n","  flex-direction: column;\n","  align-items: center;\n","  background-color: var(--sklearn-color-background);\n","  padding-right: 1em;\n","  padding-left: 1em;\n","}\n","\n","\n","/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n","clickable and can be expanded/collapsed.\n","- Pipeline and ColumnTransformer use this feature and define the default style\n","- Estimators will overwrite some part of the style using the `sk-estimator` class\n","*/\n","\n","/* Pipeline and ColumnTransformer style (default) */\n","\n","#sk-container-id-1 div.sk-toggleable {\n","  /* Default theme specific background. It is overwritten whether we have a\n","  specific estimator or a Pipeline/ColumnTransformer */\n","  background-color: var(--sklearn-color-background);\n","}\n","\n","/* Toggleable label */\n","#sk-container-id-1 label.sk-toggleable__label {\n","  cursor: pointer;\n","  display: block;\n","  width: 100%;\n","  margin-bottom: 0;\n","  padding: 0.5em;\n","  box-sizing: border-box;\n","  text-align: center;\n","}\n","\n","#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n","  /* Arrow on the left of the label */\n","  content: \"▸\";\n","  float: left;\n","  margin-right: 0.25em;\n","  color: var(--sklearn-color-icon);\n","}\n","\n","#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n","  color: var(--sklearn-color-text);\n","}\n","\n","/* Toggleable content - dropdown */\n","\n","#sk-container-id-1 div.sk-toggleable__content {\n","  max-height: 0;\n","  max-width: 0;\n","  overflow: hidden;\n","  text-align: left;\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-0);\n","}\n","\n","#sk-container-id-1 div.sk-toggleable__content.fitted {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-0);\n","}\n","\n","#sk-container-id-1 div.sk-toggleable__content pre {\n","  margin: 0.2em;\n","  border-radius: 0.25em;\n","  color: var(--sklearn-color-text);\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-0);\n","}\n","\n","#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n","  /* unfitted */\n","  background-color: var(--sklearn-color-fitted-level-0);\n","}\n","\n","#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n","  /* Expand drop-down */\n","  max-height: 200px;\n","  max-width: 100%;\n","  overflow: auto;\n","}\n","\n","#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n","  content: \"▾\";\n","}\n","\n","/* Pipeline/ColumnTransformer-specific style */\n","\n","#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n","  color: var(--sklearn-color-text);\n","  background-color: var(--sklearn-color-unfitted-level-2);\n","}\n","\n","#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n","  background-color: var(--sklearn-color-fitted-level-2);\n","}\n","\n","/* Estimator-specific style */\n","\n","/* Colorize estimator box */\n","#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-2);\n","}\n","\n","#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-2);\n","}\n","\n","#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n","#sk-container-id-1 div.sk-label label {\n","  /* The background is the default theme color */\n","  color: var(--sklearn-color-text-on-default-background);\n","}\n","\n","/* On hover, darken the color of the background */\n","#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n","  color: var(--sklearn-color-text);\n","  background-color: var(--sklearn-color-unfitted-level-2);\n","}\n","\n","/* Label box, darken color on hover, fitted */\n","#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n","  color: var(--sklearn-color-text);\n","  background-color: var(--sklearn-color-fitted-level-2);\n","}\n","\n","/* Estimator label */\n","\n","#sk-container-id-1 div.sk-label label {\n","  font-family: monospace;\n","  font-weight: bold;\n","  display: inline-block;\n","  line-height: 1.2em;\n","}\n","\n","#sk-container-id-1 div.sk-label-container {\n","  text-align: center;\n","}\n","\n","/* Estimator-specific */\n","#sk-container-id-1 div.sk-estimator {\n","  font-family: monospace;\n","  border: 1px dotted var(--sklearn-color-border-box);\n","  border-radius: 0.25em;\n","  box-sizing: border-box;\n","  margin-bottom: 0.5em;\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-0);\n","}\n","\n","#sk-container-id-1 div.sk-estimator.fitted {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-0);\n","}\n","\n","/* on hover */\n","#sk-container-id-1 div.sk-estimator:hover {\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-2);\n","}\n","\n","#sk-container-id-1 div.sk-estimator.fitted:hover {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-2);\n","}\n","\n","/* Specification for estimator info (e.g. \"i\" and \"?\") */\n","\n","/* Common style for \"i\" and \"?\" */\n","\n",".sk-estimator-doc-link,\n","a:link.sk-estimator-doc-link,\n","a:visited.sk-estimator-doc-link {\n","  float: right;\n","  font-size: smaller;\n","  line-height: 1em;\n","  font-family: monospace;\n","  background-color: var(--sklearn-color-background);\n","  border-radius: 1em;\n","  height: 1em;\n","  width: 1em;\n","  text-decoration: none !important;\n","  margin-left: 1ex;\n","  /* unfitted */\n","  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n","  color: var(--sklearn-color-unfitted-level-1);\n","}\n","\n",".sk-estimator-doc-link.fitted,\n","a:link.sk-estimator-doc-link.fitted,\n","a:visited.sk-estimator-doc-link.fitted {\n","  /* fitted */\n","  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n","  color: var(--sklearn-color-fitted-level-1);\n","}\n","\n","/* On hover */\n","div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",".sk-estimator-doc-link:hover,\n","div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",".sk-estimator-doc-link:hover {\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-3);\n","  color: var(--sklearn-color-background);\n","  text-decoration: none;\n","}\n","\n","div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",".sk-estimator-doc-link.fitted:hover,\n","div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",".sk-estimator-doc-link.fitted:hover {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-3);\n","  color: var(--sklearn-color-background);\n","  text-decoration: none;\n","}\n","\n","/* Span, style for the box shown on hovering the info icon */\n",".sk-estimator-doc-link span {\n","  display: none;\n","  z-index: 9999;\n","  position: relative;\n","  font-weight: normal;\n","  right: .2ex;\n","  padding: .5ex;\n","  margin: .5ex;\n","  width: min-content;\n","  min-width: 20ex;\n","  max-width: 50ex;\n","  color: var(--sklearn-color-text);\n","  box-shadow: 2pt 2pt 4pt #999;\n","  /* unfitted */\n","  background: var(--sklearn-color-unfitted-level-0);\n","  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n","}\n","\n",".sk-estimator-doc-link.fitted span {\n","  /* fitted */\n","  background: var(--sklearn-color-fitted-level-0);\n","  border: var(--sklearn-color-fitted-level-3);\n","}\n","\n",".sk-estimator-doc-link:hover span {\n","  display: block;\n","}\n","\n","/* \"?\"-specific style due to the `<a>` HTML tag */\n","\n","#sk-container-id-1 a.estimator_doc_link {\n","  float: right;\n","  font-size: 1rem;\n","  line-height: 1em;\n","  font-family: monospace;\n","  background-color: var(--sklearn-color-background);\n","  border-radius: 1rem;\n","  height: 1rem;\n","  width: 1rem;\n","  text-decoration: none;\n","  /* unfitted */\n","  color: var(--sklearn-color-unfitted-level-1);\n","  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n","}\n","\n","#sk-container-id-1 a.estimator_doc_link.fitted {\n","  /* fitted */\n","  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n","  color: var(--sklearn-color-fitted-level-1);\n","}\n","\n","/* On hover */\n","#sk-container-id-1 a.estimator_doc_link:hover {\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-3);\n","  color: var(--sklearn-color-background);\n","  text-decoration: none;\n","}\n","\n","#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-3);\n","}\n","</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(gamma=&#x27;auto&#x27;, kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;SVC<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.svm.SVC.html\">?<span>Documentation for SVC</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>SVC(gamma=&#x27;auto&#x27;, kernel=&#x27;linear&#x27;)</pre></div> </div></div></div></div>"],"text/plain":["SVC(gamma='auto', kernel='linear')"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["# Classifier - Algorithm - SVM\n","# fit the training dataset on the classifier\n","SVM = svm.SVC(C=1.0, kernel='linear', degree=3, gamma='auto')\n","SVM.fit(Train_X_Tfidf,y_train)\n"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Submission file created!\n"]}],"source":["# Predict sentiments for the test set\n","y_test_predictions = SVM.predict(Test_X_Tfidf)\n","\n","# Assuming `test` dataframe has a column `PhraseId`\n","submission = pd.DataFrame({\n","    \"PhraseId\": test[\"PhraseId\"],  # Use the PhraseId from the test set\n","    \"Sentiment\": y_test_predictions  # Use the predictions generated by the model\n","})\n","\n","# Save to CSV\n","submission.to_csv(\"svmSubmission.csv\", index=False)\n","print(\"Submission file created!\")\n","\n"]}],"metadata":{"colab":{"gpuType":"T4","name":"","provenance":[{"file_id":"https://github.com/hasankhwaja/Movie-Sentiment-Analysis-/blob/main/SVM.ipynb","timestamp":1732294264326}],"version":""},"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.4"}},"nbformat":4,"nbformat_minor":0}
